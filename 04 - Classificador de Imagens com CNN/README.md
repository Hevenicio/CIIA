<div align="center">
  <img src="imgs/CNN.gif" alt="Demonstra√ß√£o da CNN" width="800"/>
</div>

# O que s√£o Redes Neurais Convolucionais (CNNs)?

Redes Neurais Convolucionais (Convolutional Neural Network - CNN, em ingl√™s) s√£o arquiteturas de aprendizado profundo projetadas para processamento de dados com estrutura espacial, como imagens. O grande diferencial das CNNs √© a habilidade de identificar automaticamente caracter√≠sticas relevantes nas imagens, sem precisar de interven√ß√£o humana para esse processo. A CNN √© composta por camadas
espec√≠ficas, cada uma desempenhando uma fun√ß√£o essencial no aprendizado e extra√ß√£o
de caracter√≠sticas.

###

A ordem das camadas em uma CNN pode variar dependendo da arquitetura espec√≠fica, mas geralmente segue a especificada na Figura 1.

<div align="center">
  <img src="imgs/CNN.png" alt="Rede CNN" width="750"/><br>
  <span style="display:block; text-align:center;"><b>Figura 1:</b> Diagrama representando uma Rede Neural Convolucional (CNN).</span>
</div>

## As principais etapas de funcionamento de uma CNN s√£o:

- **Camada de Entrada:** recebe e prepara a imagem, transformando cada pixel em um valor process√°vel;

- **Camadas de Convolu√ß√£o:** as camadas de convolu√ß√£o s√£o a ess√™ncia das CNNs.
Cada camada de convolu√ß√£o √© composta por um conjunto de filtros (ou kernels) que deslizam pela imagem, calculando a convolu√ß√£o entre o filtro e uma regi√£o localizada na imagem. Essa opera√ß√£o de convolu√ß√£o resulta em mapas de caracter√≠sticas que destacam a presen√ßa de caracter√≠sticas espec√≠ficas, como bordas, texturas ou padr√µes em diferentes partes da imagem. Cada filtro aprende a detectar um tipo particular de caracter√≠stica, e a rede combina m√∫ltiplos filtros para capturar uma variedade de caracter√≠sticas em v√°rias escalas e n√≠veis de abstra√ß√£o. A Figura 2 esquematiza esse conceito;

###

<div align="center">
  <img src="imgs/Conv_CIIA.jpg" alt="Convolu√ß√£o" width="600"/><br>
  <span style="display:block; text-align:center;"><b>Figura 2:</b> Um exemplo de convolu√ß√£o entre entrada I(5√ó5√ó1) e um kernel K(3√ó3√ó1) com passo de 1.</span>
</div>

###
Abaixo temos ilustra√ß√µes esquematizam como esse processo acontece:

<div align="center">
  <img src="imgs/conv.gif" alt="Convolu√ß√£o" width="400" style="margin-right: 50px;"/>
  <img src="imgs/cnn_gato.gif" alt="CNN classificando gato" width="250"/>
</div>

###
- **Camadas de Ativa√ß√£o:** ap√≥s cada camada de convolu√ß√£o, √© aplicada uma fun√ß√£o
de ativa√ß√£o n√£o linear para introduzir n√£o linearidade e melhorar a capacidade de aprendizado na rede. A fun√ß√£o de ativa√ß√£o √© aplicada elemento a elemento aos mapas de caracter√≠sticas gerados pela convolu√ß√£o. A fun√ß√£o ReLU (Rectified Linear Unit, em ingl√™s) √© amplamente usada nas CNNs.

  - **Por que ReLU √© a escolha padr√£o?**
  
      - A fun√ß√£o **ReLU** √© amplamente usada nas CNNs modernas, definida como `f(x) = max(0, x)`. Embora fun√ß√µes cl√°ssicas como Sigmoid e Tanh tenham sido usadas historicamente, elas apresentam o **problema do gradiente desaparecente**: suas derivadas s√£o limitadas a valores pequenos (Sigmoid entre 0 e 0,25, Tanh entre 0 e 1), fazendo com que os gradientes se tornem exponencialmente menores durante a retropropaga√ß√£o em redes profundas, dificultando o aprendizado nas camadas iniciais, a Figura 3 esquematiza a compara√ß√£o dessas tr√™s fun√ß√µes.
      
      - A ReLU resolve esse problema porque sua derivada √© constantemente 1 para entradas positivas, permitindo que os gradientes fluam sem perder intensidade atrav√©s de m√∫ltiplas camadas. Al√©m disso, ReLU √© computacionalmente eficiente (apenas uma opera√ß√£o de compara√ß√£o) e promove **esparsidade** na rede ao desativar neur√¥nios com entradas negativas, o que funciona como uma forma de regulariza√ß√£o impl√≠cita. Essas vantagens tornaram poss√≠vel o treinamento de redes muito profundas, como ResNet e VGG, que seriam impratic√°veis com sigmoid ou tanh.

      <div align="center">
        <img src="imgs/ativa.png" alt="ReLU" width="900"/><br>
        <span style="display:block; text-align:center;"><b>Figura 3:</b> Compara√ß√£o entre fun√ß√µes de ativa√ß√£o: Sigmoid, Tanh e ReLU.</span>
      </div>
###

- **Camadas de Pooling:** estas camadas s√£o respons√°veis por reduzir a dimensionalidade espacial dos mapas de caracter√≠sticas gerados pelas camadas de convolu√ß√£o. O pooling √© uma t√©cnica que divide o mapa de caracter√≠sticas em regi√µes e realiza uma opera√ß√£o, como selecionar o valor m√°ximo (max pooling) ou calcular a m√©dia (average pooling), para obter um valor representativo para cada regi√£o. Essa redu√ß√£o da resolu√ß√£o espacial permite que a rede se torne mais robusta a pequenas varia√ß√µes na posi√ß√£o das caracter√≠sticas e tamb√©m reduz o n√∫mero de par√¢metros na rede, tornando-a mais eficiente computacionalmente.

###

- **Camadas Totalmente Conectadas:** estas camadas finais s√£o respons√°veis por mapear as caracter√≠sticas extra√≠das para as classes de destino. Elas incorporam a capacidade de generaliza√ß√£o da rede neural, permitindo que a rede tome decis√µes finais com base nas caracter√≠sticas aprendidas durante o treinamento.

###

- **Camada de Sa√≠da:** apresenta o resultado, como a classe da imagem identificada (ex: ‚Äúcachorro‚Äù ou ‚Äúgato‚Äù).

üöÄ Aplica√ß√£o: Projeto Streamlit

Para demonstrar esses conceitos em a√ß√£o, desenvolvi uma aplica√ß√£o web interativa usando Streamlit!

<div align="center">
  <img src="imgs/classificador.png" alt="classificador" width="900"/><br>
</div>



Foi utilizado um modelo CNN (com arquitetura Keras/TensorFlow) treinado para classificar imagens de gatos üê± e cachorros üê∂.
Nele √© poss√≠vel fazer o upload da sua pr√≥pria imagem e ver o modelo tomar a decis√£o em tempo real, mostrando a classe prevista e o n√≠vel de confian√ßa.
Foi um projeto excelente para demonstrar o conhecimento te√≥rico e transform√°-lo em uma ferramenta pr√°tica e funcional.

üîó Convido voc√™ a testar o app e explorar o c√≥digo-fonte completo no meu reposit√≥rio do GitHub:
[REPOSIT√ìRIO GITHUB](https://github.com/Hevenicio/CIIA/tree/main/04%20-%20Classificador%20de%20Imagens%20com%20CNN)

#DeepLearning  #InteligenciaArtificial #IA #CNN #Python #Streamlit #TensorFlow #Keras #VisaoComputacional #DataScience #MachineLearning #CIIA