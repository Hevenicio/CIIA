{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Verificar o ambiente"
      ],
      "metadata": {
        "id": "0bzA45_TOKYg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "n5fTZZCMyavY",
        "outputId": "7796332c-3b7c-4745-e4b5-6003c2d29cbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Oct  6 01:19:53 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   30C    P0             43W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalando bibliotecas e modelos necess√°rios:"
      ],
      "metadata": {
        "id": "u3pBr3wV_Urk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria a pasta para o modelo\n",
        "!mkdir -p modelo\n",
        "\n",
        "# Baixa o modelo RealESRGAN_x4plus para a pasta criada\n",
        "!wget -q https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P modelo"
      ],
      "metadata": {
        "id": "nhjsg3KXF4Gk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logo\n",
        "!mkdir -p img\n",
        "!wget -q https://github.com/Hevenicio/CIIA/blob/main/03%20-%20Restaurador%20de%20Imagens%20com%20IA/img/logo_CIIA.png -P img"
      ],
      "metadata": {
        "id": "CCp8_3dopruv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "!ls /content/modelo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Naw6R0lYW4pU",
        "outputId": "9235a132-a262-4b20-8640-d360c7156c26"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "img  modelo  sample_data\n",
            "RealESRGAN_x4plus.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "\n",
        "numpy\n",
        "opencv-python\n",
        "Pillow\n",
        "torch>=1.7\n",
        "torchvision>=0.8.0\n",
        "tqdm\n",
        "huggingface-hub\n",
        "basicsr\n",
        "facexlib\n",
        "gfpgan\n",
        "ffmpeg-python\n",
        "streamlit\n",
        "pyngrok\n",
        "py-real-esrgan\n",
        "huggingface-hub==0.20.3\n",
        "streamlit-image-comparison"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SnFus5TDZioc",
        "outputId": "9415d5a2-a986-497f-a54e-c2ad0f0a0a6f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -r requirements.txt"
      ],
      "metadata": {
        "id": "8FueGryCDOXO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criando o Scrip principal"
      ],
      "metadata": {
        "id": "m7QVhuIX_wKy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "aSOP-HneAIq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "from streamlit_image_comparison import image_comparison\n",
        "from py_real_esrgan.model import RealESRGAN\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import torch\n",
        "\n",
        "# --- CSS Simples para Estilizar o Uploader ---\n",
        "st.markdown(\"\"\"\n",
        "    <style>\n",
        "        .st-emotion-cache-1jicfl2 {\n",
        "            border: 2px dashed #a8a8a8;\n",
        "            padding: 2rem;\n",
        "            border-radius: 0.5rem;\n",
        "            text-align: center;\n",
        "        }\n",
        "        .st-emotion-cache-1jicfl2:hover {\n",
        "            border-color: #f8f9fa;\n",
        "        }\n",
        "    </style>\n",
        "\"\"\", unsafe_allow_html = True)\n",
        "\n",
        "# --- Fun√ß√µes de Processamento com Cache ---\n",
        "@st.cache_resource\n",
        "def carregar_modelo():\n",
        "    \"\"\"\n",
        "    Carrega o modelo Real-ESRGAN. A fun√ß√£o √© armazenada em cache para\n",
        "    que o modelo n√£o seja recarregado a cada intera√ß√£o do usu√°rio.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model = RealESRGAN(device, scale = 4)\n",
        "        model_path = 'modelo/RealESRGAN_x4plus.pth'\n",
        "        model.load_weights(model_path)\n",
        "        return model\n",
        "    except FileNotFoundError:\n",
        "        st.error(\"Arquivo do modelo n√£o encontrado! Certifique-se de que 'RealESRGAN_x4plus.pth' est√° na pasta 'modelo'.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        st.error(f\"Ocorreu um erro ao carregar o modelo: {e}\")\n",
        "        return None\n",
        "\n",
        "def restaurar_imagem(imagem_pil, model):\n",
        "    \"\"\"\n",
        "    Recebe uma imagem (formato PIL), a aprimora usando o modelo e a retorna.\n",
        "    \"\"\"\n",
        "    if model is None:\n",
        "        return None\n",
        "    try:\n",
        "        sr_image = model.predict(imagem_pil)\n",
        "        return sr_image\n",
        "    except Exception as e:\n",
        "        st.error(f\"Ocorreu um erro durante o processamento da imagem: {e}\")\n",
        "        return None\n",
        "\n",
        "# --- Configura√ß√£o da P√°gina ---\n",
        "st.set_page_config(layout = 'centered', page_icon = '‚ú®üñºÔ∏è', page_title = 'Restaurador de Imagens com IA')\n",
        "\n",
        "# --- Interface Principal ---\n",
        "st.markdown(\"<h2 style='text-align: center;'>Restaurador de Imagens com IA ‚ú®üñºÔ∏è</h2>\", unsafe_allow_html = True)\n",
        "st.markdown(\"<h5 style='text-align: center;'>D√™ vida nova a fotos antigas, borradas ou de baixa qualidade.</h5>\", unsafe_allow_html = True)\n",
        "st.markdown(\"---\")\n",
        "\n",
        "\n",
        "# Carrega o modelo de IA\n",
        "model = carregar_modelo()\n",
        "\n",
        "with st.sidebar:\n",
        "    #st.logo('img/logo_CIIA.png', size = 'large', )\n",
        "    st.image('img/logo_CIIA.png', use_container_width = True)\n",
        "\n",
        "    st.markdown('# üì§ Envie uma imagem')\n",
        "    #uploaded_file = st.file_uploader('-', type = ['jpg', 'jpeg', 'png'],  help = 'Formatos suportados: JPG, JPEG, PNG', label_visibility = 'collapsed')\n",
        "    uploaded_file = st.file_uploader('Selecione uma imagem para restaurar', type = ['png', 'jpeg', 'jpg'], label_visibility = 'collapsed')\n",
        "\n",
        "\n",
        "if uploaded_file is not None and model is not None:\n",
        "    if 'file_id' not in st.session_state or st.session_state.file_id != uploaded_file.file_id:\n",
        "        st.session_state.file_id = uploaded_file.file_id\n",
        "        st.session_state.restored_image = None\n",
        "\n",
        "    imagem_original = Image.open(uploaded_file).convert('RGB')\n",
        "\n",
        "    # Bot√£o de restaura√ß√£o fica vis√≠vel o tempo todo\n",
        "    if st.sidebar.button('‚ú® Aplicar Restaura√ß√£o', width = 'content', type = 'primary'):\n",
        "        with st.spinner('A image est√° sendo aprimorada... Por favor, aguarde.'):\n",
        "            imagem_restaurada = restaurar_imagem(imagem_original, model)\n",
        "            if imagem_restaurada:\n",
        "                st.session_state.restored_image = imagem_restaurada\n",
        "\n",
        "    # L√≥gica de exibi√ß√£o condicional\n",
        "    if st.session_state.restored_image is None:\n",
        "        # Se AINDA N√ÉO restaurou, mostra s√≥ a original\n",
        "        st.sidebar.image(imagem_original, width = 'content', use_container_width = True)\n",
        "    else:\n",
        "        image_comparison(\n",
        "            img1 = imagem_original,\n",
        "            img2 = st.session_state.restored_image,\n",
        "            label1 = 'Original',\n",
        "            label2 = 'Restaurada',\n",
        "            width = 700,\n",
        "            starting_position = 50,\n",
        "            show_labels = True,\n",
        "            make_responsive = True,\n",
        "            in_memory = True,\n",
        "        )\n",
        "\n",
        "        st.divider()\n",
        "\n",
        "        buf = BytesIO()\n",
        "        st.session_state.restored_image.save(buf, format = \"PNG\")\n",
        "        byte_im = buf.getvalue()\n",
        "\n",
        "        nome_base = uploaded_file.name.rsplit('.', 1)[0]\n",
        "        nome_saida = f'{nome_base}_restaurada.png'\n",
        "\n",
        "        st.sidebar.write('###### **Fa√ßa o download da imagem restaurada:**')\n",
        "        st.sidebar.download_button(\n",
        "            label = \"Baixar em PNG\",\n",
        "            data = byte_im,\n",
        "            file_name = nome_saida,\n",
        "            mime = \"image/png\",\n",
        "            width = 'content'\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "54bU3rc9_vny",
        "outputId": "f3635bad-d8bf-468e-8ac2-bae00b847bcf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "KXJmyjarAJ0J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Via NGROK\n",
        "# Este c√≥digo ir√° parar processos antigos, iniciar o app e mostrar a URL correta:"
      ],
      "metadata": {
        "id": "XjPrP0OxAMjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Para qualquer processo anterior do Streamlit ou ngrok para evitar erros\n",
        "!kill -9 $(lsof -t -i:8501) &> /dev/null\n",
        "!pkill ngrok &> /dev/null\n",
        "\n",
        "from google.colab import userdata\n",
        "from pyngrok import ngrok\n",
        "import time\n",
        "import os\n",
        "\n",
        "# 2. Verifica se o app.py existe\n",
        "if not os.path.exists('app.py'):\n",
        "    print(\"‚ùå Erro: O arquivo 'app.py' n√£o foi encontrado.\")\n",
        "    print(\"Por favor, execute a c√©lula que cria o '%%writefile app.py' primeiro.\")\n",
        "else:\n",
        "    # 3. Pega a chave do ngrok dos Secrets do Colab\n",
        "    try:\n",
        "        ngrok_key = userdata.get('key_ngrok')\n",
        "        if not ngrok_key:\n",
        "            raise ValueError(\"A chave 'key_ngrok' est√° vazia ou n√£o foi encontrada.\")\n",
        "\n",
        "        print(\"üîë Chave do ngrok encontrada. Autenticando...\\n\")\n",
        "        ngrok.set_auth_token(ngrok_key)\n",
        "\n",
        "        # 4. Inicia o servidor Streamlit em background\n",
        "        print(\"üöÄ Iniciando o servidor Streamlit em segundo plano...\\n\")\n",
        "        os.system(\"streamlit run app.py &\")\n",
        "\n",
        "        # Pequena pausa para garantir que o servidor subiu\n",
        "        time.sleep(5)\n",
        "\n",
        "        # 5. Conecta o ngrok √† porta 8501 e obt√©m a URL p√∫blica\n",
        "        print(\"üîó Criando o t√∫nel p√∫blico com ngrok...\")\n",
        "        public_url = ngrok.connect(8501)\n",
        "\n",
        "        print(\"\\n\\n‚úÖ TUDO PRONTO! ‚úÖ\")\n",
        "        print(\"üëáüëáüëá Clique no link abaixo para abrir seu aplicativo üëáüëáüëá\\n\")\n",
        "        print(public_url)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Ocorreu um erro: {e}\")\n",
        "        print(\"Por favor, verifique se sua chave 'key_ngrok' est√° correta nos Secrets do Colab.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "XQEMhzscAH4C",
        "outputId": "bbe5cd6f-3904-4e11-d7f1-4eb7c69db1a0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîë Chave do ngrok encontrada. Autenticando...\n",
            "\n",
            "üöÄ Iniciando o servidor Streamlit em segundo plano...\n",
            "\n",
            "üîó Criando o t√∫nel p√∫blico com ngrok...\n",
            "\n",
            "\n",
            "‚úÖ TUDO PRONTO! ‚úÖ\n",
            "üëáüëáüëá Clique no link abaixo para abrir seu aplicativo üëáüëáüëá\n",
            "\n",
            "NgrokTunnel: \"https://thermodynamic-cortez-palaeobotanical.ngrok-free.dev\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}